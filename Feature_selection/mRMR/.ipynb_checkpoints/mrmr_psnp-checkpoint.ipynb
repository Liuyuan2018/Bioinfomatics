{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176\n",
      "1176\n",
      "131\n",
      "131\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "File temp_file2.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-8f59db591617>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mchild2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'java -jar arff2csv.jar temp_file.arff temp_file2.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mchild2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[0mmrmr_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"temp_file2.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[0mmrmr_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmrmr_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File temp_file2.csv does not exist"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding:utf-8\n",
    "import sklearn.decomposition.PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import math\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import subprocess\n",
    "\n",
    "\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall==0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "final_out_to_excel=[]\n",
    "row0 = [u'特征集', u'样本个数', u'分类器', u'Accuracy', u'Precision', u'Recall', u'SN', u'SP',\n",
    "                u'Gm', u'F_measure', u'F_score', u'MCC', u'ROC曲线面积', u'tp', u'fn', u'fp', u'tn']\n",
    "final_out_to_excel.append(row0)\n",
    "seq=[]\n",
    "m6a_2614_sequence=\"m6a_data.txt\"\n",
    "RNA_code='ACGU'\n",
    "k=1\n",
    "interval=1\n",
    "select_num=40\n",
    "divided_num=10.0\n",
    "division_num=10\n",
    "fh=open(m6a_2614_sequence)\n",
    "for line in fh:\n",
    "    if line.startswith('>'):\n",
    "        continue\n",
    "    else:\n",
    "        seq.append(line.replace('\\n',''))\n",
    "fh.close()\n",
    "\n",
    "def make_kmer_list(k, alphabet):\n",
    "    try:\n",
    "        return [\"\".join(e) for e in itertools.product(alphabet, repeat=k)]\n",
    "    except TypeError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0, alphabet must be a string.\")\n",
    "        raise TypeError\n",
    "    except ValueError:\n",
    "        print(\"TypeError: k must be an inter and larger than 0\")\n",
    "        raise ValueError\n",
    "positive_seq=seq[:len(seq)/2]\n",
    "# X_train, X_test, y_train, y_test = cross_validation.train_test_split(train_data, train_target, test_size=0.1, random_state=0)\n",
    "negative_seq=seq[len(seq)/2:]\n",
    "kf = KFold(n_splits=division_num,shuffle=False)  \n",
    "for select_num in xrange(40,50):\n",
    "    y_pred_prob_all=[]\n",
    "    y_pred_all=[]\n",
    "    Y_all=[]\n",
    "    ACC_all=0\n",
    "    precision_all=0\n",
    "    recall_all=0\n",
    "    SN_all=0\n",
    "    SP_all=0\n",
    "    GM_all=0\n",
    "    TP_all=0\n",
    "    TN_all=0\n",
    "    FP_all=0\n",
    "    FN_all=0\n",
    "    F_measure_all=0\n",
    "    F1_Score_all=0\n",
    "    pos_all=0\n",
    "    neg_all=0\n",
    "    MCC_all=0\n",
    "    for train_index , test_index in kf.split(positive_seq):  \n",
    "        positive_df=pd.DataFrame(positive_seq)\n",
    "        positive_x_train=positive_df.iloc[train_index,:]\n",
    "        positive_y_train=positive_df.iloc[test_index,:]\n",
    "        negative_df=pd.DataFrame(negative_seq)\n",
    "        negative_x_train=negative_df.iloc[train_index,:]\n",
    "        negative_y_train=negative_df.iloc[test_index,:]\n",
    "        positive_negative_x_train=pd.concat([positive_x_train,negative_x_train],axis=0)\n",
    "        positive_negative_y_train=pd.concat([positive_y_train,negative_y_train],axis=0)\n",
    "    # for interval in xrange(1,k+1):\n",
    "        final_seq_value=[[0 for ii in xrange(len(seq[0])-interval)] for jj in xrange(len(positive_negative_x_train))]\n",
    "        code_values=make_kmer_list(interval,RNA_code)\n",
    "        code_len=len(code_values)\n",
    "        positive_seq_value=[[0 for jj in xrange(len(seq[0])-interval)] for ii in xrange(code_len)]\n",
    "        negative_seq_value=[[0 for jj in xrange(len(seq[0])-interval)] for ii in xrange(code_len)]\n",
    "        for i,line_value in enumerate(positive_x_train.values):\n",
    "            for j,code_value in enumerate(line_value[0]):\n",
    "                if j<= len(line_value[0])-interval-1 :\n",
    "                    for p,c_value in enumerate(code_values):\n",
    "                        if c_value==line_value[0][j:j+interval]:\n",
    "                            positive_seq_value[p][j]+=1\n",
    "        positive_seq_value=np.matrix(positive_seq_value)*1.0/(len(seq)/2)\n",
    "        for i,line_value in enumerate(negative_x_train.values):\n",
    "            for j,code_value in enumerate(line_value[0]):\n",
    "                if j<= len(line_value[0])-interval-1 :\n",
    "                    for p,c_value in enumerate(code_values):\n",
    "                        if c_value==line_value[0][j:j+interval]:\n",
    "                            negative_seq_value[p][j]+=1\n",
    "        negative_seq_value=np.matrix(negative_seq_value)*1.0/(len(seq)/2)\n",
    "        for i,line_value in enumerate(positive_negative_x_train.values):\n",
    "            for j,code_value in enumerate(line_value[0]):\n",
    "                if j<= len(line_value[0])-interval-1 :\n",
    "                    for p,c_value in enumerate(code_values):\n",
    "                        if c_value==line_value[0][j:j+interval]:\n",
    "                              final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "        y_final_seq_value=[[0 for ii in xrange(len(seq[0])-interval)] for jj in xrange(len(positive_negative_y_train))]\n",
    "        \n",
    "\n",
    "        for i,line_value in enumerate(positive_negative_y_train.values):\n",
    "            for j,code_value in enumerate(line_value[0]):\n",
    "                if j<= len(line_value[0])-interval-1 :\n",
    "                    for p,c_value in enumerate(code_values):\n",
    "                        if c_value==line_value[0][j:j+interval]:\n",
    "                              y_final_seq_value[i][j]=positive_seq_value[p,j]-negative_seq_value[p,j]\n",
    "        \n",
    "#         final_seq_value_0=final_seq_value[0:len(final_seq_value)/2]\n",
    "#         final_seq_value_1=final_seq_value[len(final_seq_value)/2:len(final_seq_value)]\n",
    "#         y_final_seq_value_0=y_final_seq_value[0:len(y_final_seq_value)/2]\n",
    "#         y_final_seq_value_1=y_final_seq_value[len(y_final_seq_value)/2:len(y_final_seq_value)]\n",
    "#         all_seq=final_seq_value_0\n",
    "#         all_seq.extend(y_final_seq_value_0)\n",
    "#         all_seq.extend(final_seq_value_1)\n",
    "#         all_seq.extend(y_final_seq_value_1)\n",
    "#         all_seq=pd.DataFrame(all_seq)\n",
    "#         all_seq.to_csv('temp_file.csv')\n",
    "        final_seq_value=pd.DataFrame(final_seq_value)\n",
    "        y_final_seq_value=pd.DataFrame(y_final_seq_value)\n",
    "#         temp_file=pd.concat([final_seq_value,y_final_seq_value],axis=0)\n",
    "#         temp_file=pd.DataFrame(temp_file).to_csv('temp_file.csv')\n",
    "#         fina_seq_value_0=final_seq_value.iloc[xrange(len(final_seq_value)/2),:]\n",
    "#         fina_seq_value_1=final_seq_value.iloc[xrange(len(final_seq_value)/2,len(final_seq_value)),:]\n",
    "#         y_final_seq_value_0=y_final_seq_value.iloc[xrange(len(y_final_seq_value)/2),:]\n",
    "#         y_final_seq_value_1=y_final_seq_value.iloc[xrange(len(y_final_seq_value)/2,len(y_final_seq_value)),:]\n",
    "        \n",
    "        \n",
    "#         child3=subprocess.Popen('./mrmr -i temp_file.csv -n %d >temp_file.mrmrout'%select_num,shell=True)\n",
    "#         child3.wait\n",
    "#         child4=subprocess.Popen('java -jar mrmr_to_arff.jar temp_file.mrmrout temp_file.arff -f 20 -c 7 1 2 3 4 5 6 7',shell=True)\n",
    "#         child4.wait\n",
    "#         child2=subprocess.Popen('java -jar arff2csv.jar temp_file.arff temp_file2.csv',shell=True)\n",
    "#         child2.wait\n",
    "#         mrmr_data=pd.read_csv(\"temp_file2.csv\")\n",
    "#         mrmr_data=mrmr_data.values\n",
    "\n",
    "        \n",
    "        X_train = np.array(mrmr_data.iloc[xrange(len(train_index*2)),:])\n",
    "        Y_train = list(map(lambda x: 1, xrange(len(X_train) / 2)))\n",
    "        Y2_train = list(map(lambda x: 0, xrange(len(X_train) / 2)))\n",
    "        Y_train.extend(Y2_train)\n",
    "        Y_train = np.array(Y_train)\n",
    "\n",
    "        X_test = np.array(mrmr_data.iloc[xrange(len(test_index*2)),:])\n",
    "        Y_test  = list(map(lambda x: 1, xrange(len(y_final_seq_value) / 2)))\n",
    "        Y2_test  = list(map(lambda x: 0, xrange(len(y_final_seq_value) / 2)))\n",
    "        Y_test.extend(Y2_test )\n",
    "        Y_test  = np.array(Y_test)\n",
    "\n",
    "        svc = svm.SVC(probability=True)\n",
    "        parameters = {'kernel': ['rbf'], 'C':map(lambda x:2**x,np.linspace(-2,5,28)), 'gamma':map(lambda x:2**x,np.linspace(-5,2,28))}\n",
    "        clf = GridSearchCV(svc, parameters, cv=10, n_jobs=8, scoring='accuracy')\n",
    "        clf.fit(X_train, Y_train)\n",
    "        C=clf.best_params_['C']\n",
    "        y_pred_prob=clf.predict_proba(X_test)\n",
    "\n",
    "        gamma=clf.best_params_['gamma']\n",
    "        print 'c:',C,'gamma:',gamma\n",
    "        y_pred=clf.predict(X_test)\n",
    "\n",
    "        y_pred_prob_all.extend(y_pred_prob)\n",
    "        y_pred_all.extend(y_pred)\n",
    "        Y_all.extend(Y_test)\n",
    "        ACC=metrics.accuracy_score(Y_test,y_pred)\n",
    "        print ACC\n",
    "        precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y_test, y_pred) \n",
    "        F1_Score=metrics.f1_score(Y_test, y_pred)\n",
    "        F_measure=F1_Score\n",
    "        MCC=metrics.matthews_corrcoef(Y_test, y_pred)\n",
    "\n",
    "        pos=TP+FN\n",
    "        neg=FP+TN\n",
    "        ACC_all=ACC_all+ACC\n",
    "        print \"ACC_all:\",ACC_all\n",
    "        precision_all=precision_all+precision\n",
    "        recall_all=recall_all+recall\n",
    "        SN_all=SN_all+SN\n",
    "        SP_all=SP_all+SP\n",
    "        GM_all=GM_all+GM\n",
    "        TP_all=TP_all+TP\n",
    "        TN_all=TN_all+TN\n",
    "        FP_all=FP_all+FP\n",
    "        FN_all=FN_all+FN\n",
    "        F_measure_all=F_measure_all+F_measure\n",
    "        F1_Score_all=F1_Score_all+F1_Score\n",
    "        pos_all=pos_all+pos\n",
    "        neg_all=neg_all+neg\n",
    "        MCC_all=MCC_all+MCC\n",
    "#     all_y=[np.array(Y_all).astype(int),np.array(y_pred_all).astype(int),np.array(y_pred_prob_all).astype(list)[:,1]]\n",
    "#     pd.DataFrame(np.matrix(all_y).T).to_csv('independent_test_with_mrmr%d.csv'%select_num,header=None,index=False)\n",
    "#     fpr, tpr, thresholds = roc_curve(np.array(Y_all).T, list(np.array(y_pred_prob_all).astype(list)[:,1]))\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "   \n",
    "#     savedata=[str(X_train.shape[1]),\"正\"+str(pos_all)+'负'+str(neg_all),'svm'+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC_all/divided_num,precision_all/divided_num, recall_all/divided_num,SN_all/divided_num,\n",
    "#                 SP_all/divided_num, GM_all/divided_num,F_measure_all/divided_num,F1_Score_all/divided_num,MCC_all/divided_num,roc_auc,TP_all,\n",
    "#                 FN_all,FP_all,TN_all]\n",
    "#     final_out_to_excel.append(savedata)\n",
    "# print savedata\n",
    "# pd.DataFrame(final_out_to_excel).to_excel(\"PSNP_mrmr.xlsx\",sheet_name=\"independent_test\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('temp_file.csv',index_col=None)\n",
    "data=data.values\n",
    "for i,value in enumerate(data):\n",
    "    if(i<1307):\n",
    "        data[i,0]=1\n",
    "    else:\n",
    "        data[i,0]=0\n",
    "pd.DataFrame(data).to_csv('tem.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "a=[[1,2,3],[4,5,6]]\n",
    "b=[[7,8,9],[10,11,12]]\n",
    "c=a[0:2]\n",
    "c.append(b[0])\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
